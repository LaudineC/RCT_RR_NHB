---
title: "Power computation POSAJE"
output: html_notebook
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE, warning=FALSE,fig.width = 8,fig.height = 5,fig.pos = "H" #, 
#cache.lazy = FALSE)
)
doc.type <- knitr::opts_knit$get('rmarkdown.pandoc.to')

library(pacman)
p_load(here)
p_load(officedown)
p_load(DesignLibrary)

```



```{r LoadLibraries, include=FALSE}
source(here("RScripts","LoadInstallPackages.R"), local = knitr::knit_global())
```

```{r LoadData, include=FALSE}
source(here("RScripts","LoadAllData.R"), local = knitr::knit_global())
```

```{r ImportAllFunctions, include=FALSE}
source(here("RScripts","AllFunctions.R"), local = knitr::knit_global())
```


Sample size: 1687 families minimum. This is based on power calculations using the Powerup
software with the following parameters: 

a) minimum detectable effect size for the main effect:
0.15; b) randomization procedure as described above; c) R2=40% owing mainly to baseline
information on intention to apply for ECS; d) T1=33%, T2=33% C=34%; e) blocks: 9; f) two-
tailed alpha level: 5%; g) statistical power: 80%; h) attrition at the endline: 25%.


# Most basic diagnostic

Our experiment has three randomised groups of roughly 600 mothers. The main outcome is application to any childcare, a binary variable with  `r round(mean(MainDB$ECSApp[MainDB$Assignment=="Control"],na.rm=T)*100)`% applying in the control group.

In a pure randomised experiment, we are interested in the coefficients $\hat{\beta}$ from the linear probability model:

$$
\begin{aligned}
Y=\alpha+\mathbf{Z}_{is}^\prime\beta+\epsilon\\
Y_{is}=\alpha_s+\sum_s\beta_sZ_{is}+\epsilon_{is}\\
\end{aligned}
$$
Where $Y_{is}$ equals 1 for application mother $i$ in the sub-sample of comparison pair $s$, with $s \in \{T_1-C,T_2-C,T_2-T_1\}$.
The matrix $\mathbf{Z}$ contains three binary vectors $Z_s$ for each treatment arm.

This regression model stacks pairs of treatment arms comparisons and retrieves a constant and a treatment coefficient for each pair.
Because Y is binary, standard errors needs to be heteroskedasticity robust and clustered at the individual level since there are repeated observation of the same individuals across pair comparisons.

## Model :

We specify a population of size $N$ where a unit $i$ has a potential outcome, $Y_i(Z=0)$, when it remains untreated and Z(z=1,2) potential outcomes defined according to the treatment that it receives. The effect of each treatment on the outcome of unit $i$ is equal to the difference in the potential outcome under treatment condition $z$ and the control condition: $Y_i(Z=z)−Y_i(Z=0)$.

## inquiry 


We are interested in all of the pairwise comparisons between arms: $E\left[Y(z)−Y(z^\prime)\right]$, for all $z,z^\prime \in \{0,1,2\}$


## Data strategy:

We randomly assign $\frac{k}{N}$ units to each of the treatment arms, with blocking.

## Answer strategy:

We take every pairwise difference in means corresponding to the specific estimand. 

We simulate data that closely resemble ours with a bit of simplification for clarity.

```{r, echo=TRUE}
#Sample Size
N <- nrow(MainDB %>% filter(Responded==1))

# We run two basic regression to get the share of high education parents and intention to use by education in the control group.

HighSES <- feols(HighEduc~1,MainDB)

intention <- feols(Intend~0+Educ2,MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)))



```


High SES represent `r round(HighSES$coefficients*100)`% of the population, `r round(intention$coefficients[1]*100)`% of them intend to use childcare, while only `r round(intention$coefficients[2]*100)`% of low SES do.
Using data from the control group, we can estimate the conditional means of the outcome for these subgroups:
```{r, echo=TRUE}
# 

C.means <- feols(AppCreche~0+i(Intend,Educ2),MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)) %>% filter(Assignment=="Control"),se="hetero")


D.means <- feols(Suivi_administratif1_0~0+i(Intend,Educ2),MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)) %>% filter(Assignment=="T2"),se="hetero")


# We think application baseline are divided into these 4 subgroups

Low.NoIntend <- C.means$coefficients["Intend::0:Educ2::Low-SES"]
High.NoIntend <- C.means$coefficients["Intend::0:Educ2::High-SES"]
Low.Intend <- C.means$coefficients["Intend::1:Educ2::Low-SES"]
High.Intend <- C.means$coefficients["Intend::1:Educ2::High-SES"]



```

```{r}
modelsummary(list("Application"=C.means,"Use administrative support"=D.means),gof_map = c("r.squared","rmse","nobs"))
```

Let's generate a first sample and potential outcome without intervention. We assume that our sample is *iid* (at least for now) and we first draw an education variable from a Bernoulli trial with probability given by the share of High SES in the sample. The realisation of education generates intention from a Bernoulli trial with probability depending on SES status (alternatively, we could have defined a latent propensity to use and a threshold function depending on education in a Roy model).



```{r}
# Set seed for reproducibility
set.seed(666)
# Define binary variable for education with average probability given from the HighSES regression coefficient
Educ2 = rbinom(N, size = 1, prob = HighSES$coefficients[1])

#Define intention to use as a binary variable with conditional probability different by education, drawn from the regression tables
Intend = rbinom(N,size=1,
                prob=Educ2*intention$coefficients["Educ2High-SES"]+
                  (1-Educ2)*intention$coefficients["Educ2Low-SES"])

#define Blocks with the intersection of the two variables

block=case_when(
                (Educ2==0 & Intend==0)~0,
                (Educ2==0 & Intend==1)~1,
                (Educ2==1 & Intend==0)~2,
                (Educ2==1 & Intend==1)~3
              )

# We can define the potential outcome in the absence of the program similarly:

Y0.star =
             case_when(
              (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
              (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
              (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
              (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
)

Y0=rbinom(N,size=1,prob=Y0.star)

# Y0 = rbinom(N,
#            size=1,
#            prob=
#              case_when(
#               (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
#               (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
#               (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
#               (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
# ))
# 




db0 <- data.frame(Y0,Intend,Educ2,block)

# Linear probability model of application by intention and education:
modelsummary(list("Simulated"=feols(Y0~0+i(Educ2,factor(Intend)),db0),
                  "Observed"=feols(ECSApp~0+i(Educ2,factor(Intend)),MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0),
                                                                                      Educ2=ifelse(Educ2=="High-SES",1,0)
                                                                                      ))))

```

Comparing the simulated outcome and actual data shows that our simulation works well.

Now, let's introduce our treatment.

```{r}
# We use block random assignment
Z = block_ra(blocks=block, prob_each = c(.34,.33,.33), conditions = c("0", "1", "2"))

# Like in our results, let's simulate a null effect of T1 and a 5PP itt of T2
# 

Y1 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,0,sd=.02))



Y2 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,.05,sd=.02))


Y.obs=case_when(Z==0~Y0,Z==1~Y1,Z==2~Y2)


db0 <- data.frame(db0,Y.obs,Y1,Y2,Z)%>% mutate(TE.21=Y2-Y1,TE.10=Y1-Y0,TE.20=Y2-Y0)

# like in our analysis, we build pair of comparison
db0 <- db0 %>% mutate(id=cur_group_rows()) 

T2T1 <- db0 %>% filter(Z %in% c(1,2)) %>% mutate(SubSample="T2-T1",Z1=ifelse(Z==2,1,0))
T2T0 <- db0 %>% filter(Z %in% c(0,2)) %>% mutate(SubSample="T2-C",Z1=ifelse(Z==2,1,0))
T1T0 <- db0 %>% filter(Z %in% c(0,1)) %>% mutate(SubSample="T1-C",Z1=ifelse(Z==1,1,0))

StackedDBB <- bind_rows(T2T1,T2T0,T1T0) %>% mutate(SubSampleStrata=interaction(SubSample,block),
                                                  StrataWave=block,
                                                  weights=1
                                                  )


test <- ITTSimultaneous(Y="Y.obs",treat = "Z1",DB=StackedDBB,weights = "weights")

real <- ITTSimultaneous(Y="ECSApp")


modelsummary(list("Simulation"=test$ModelSummary,"Real estimates"=real$ModelSummary))

estimand <- StackedDBB %>% group_by(SubSample) %>% summarise(TE.21=mean(TE.21,na.rm=T),TE.20=mean(TE.20,na.rm=T),TE.10=mean(TE.10,na.rm=T))

#results <- test$Tidy %>% left_join(estimand,by=c("term"="SubSample"))



```

There again, this simulation works well. Now we are ready to create a bootstrap function and simulate this experiment many time.

```{r, echo=T}

p_load(foreach)
p_load(doParallel)


s.size <- nrow(MainDB)

# get number of cores
numCores <- parallel::detectCores() # Requires library(parallel)

#print(numCores)
registerDoParallel(numCores-2)


# This function takes a constant ATE for each treatment arms, number of monte-carlo simulations, sample size and seed for replication.
# It generate news random data, assignment and estimate the treatment effects the same way we do with our analysis.
# It returns a dataframe with all estimates, standard errors, etc adjusted for simultaneous inference like we do in the paper.

BootConstantITT <- function(ATE1=0,ATE2=.05,nboot=500,N=1850,seed=666){
  
  results <- c()
  N = {{N}}

  set.seed({{seed}})
  foreach(n.boot= 1:{{nboot}},.combine=rbind) %dopar% {
 
    Educ2 = rbinom(N, size = 1, prob = HighSES$coefficients[1])

#Define intention to use as a binary variable with conditional probability different by education, drawn from the regression tables
Intend = rbinom(N,size=1,
                prob=Educ2*intention$coefficients["Educ2High-SES"]+
                  (1-Educ2)*intention$coefficients["Educ2Low-SES"])

#define Blocks with the intersection of the two variables

block=case_when(
                (Educ2==0 & Intend==0)~0,
                (Educ2==0 & Intend==1)~1,
                (Educ2==1 & Intend==0)~2,
                (Educ2==1 & Intend==1)~3
              )

# We can define the potential outcome in the absence of the program similarly:

Y0.star =
             case_when(
              (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
              (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
              (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
              (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
)

Y0=rbinom(N,size=1,prob=Y0.star)

# We use block random assignment
Z = block_ra(blocks=block, prob_each = c(.34,.33,.33), conditions = c("0", "1", "2"))

# Like in our results, let's simulate a null effect of T1 and a 5PP itt of T2
# 

Y1 = rbinom(N,
           size=1,
           #prob=Y0.star+rnorm(N,0+{{ATE1}},sd=.02)
           prob=Y0.star+{{ATE1}}
           )



Y2 = rbinom(N,
           size=1,
           #prob=Y0.star+rnorm(N,0+{{ATE2}},sd=.02)
           prob=Y0.star+{{ATE2}}
           )


Y.obs=case_when(Z==0~Y0,Z==1~Y1,Z==2~Y2)


db0 <- data.frame(Educ2,Intend,block,Y.obs,Y1,Y2,Z,Y0,Y0.star) %>% mutate(TE.21=Y2-Y1,TE.10=Y1-Y0,TE.20=Y2-Y0)

# like in our analysis, we build pair of comparison
db0 <- db0 %>% mutate(id=cur_group_rows()) 

T2T1 <- db0 %>% filter(Z %in% c(1,2)) %>% mutate(SubSample="T2-T1",Z1=ifelse(Z==2,1,0))  %>% group_by(block) %>% mutate(psscore=mean(Z1),WeightZ=Z1/(psscore)+(1-Z1)/(1-psscore)) %>% ungroup()
T2T0 <- db0 %>% filter(Z %in% c(0,2)) %>% mutate(SubSample="T2-C",Z1=ifelse(Z==2,1,0)) %>% group_by(block) %>% mutate(psscore=mean(Z1),WeightZ=Z1/(psscore)+(1-Z1)/(1-psscore)) %>% ungroup()
T1T0 <- db0 %>% filter(Z %in% c(0,1)) %>% mutate(SubSample="T1-C",Z1=ifelse(Z==1,1,0)) %>% group_by(block) %>% mutate(psscore=mean(Z1),WeightZ=Z1/(psscore)+(1-Z1)/(1-psscore)) %>% ungroup()

StackedDB <- bind_rows(T2T1,T2T0,T1T0) %>% mutate(SubSampleStrata=interaction(SubSample,block),
                                                  StrataWave=block,
                                                  weights=WeightZ
                                                  )


estimates <- ITTSimultaneous(Y="Y.obs",treat = "Z1",DB=StackedDB,weights = "weights")

results <- estimates$Tidy %>% mutate(Boot=n.boot)

estimand <- StackedDB %>% group_by(SubSample) %>% summarise(TE.21=mean(TE.21,na.rm=T),TE.20=mean(TE.20,na.rm=T),TE.10=mean(TE.10,na.rm=T))

results <- results %>% left_join(estimand,by=c("term"="SubSample"))

#results %>% left_join(estimand,by=c("term"="SubSample")) #%>% mutate(bias=estimate-estimand)


  } -> All.results
  
  return(All.results)

}

testBoot <- BootConstantITT(nboot = 500,ATE1 = 0,ATE2=.05,N=sum(MainDB$Responded))




```

We can plot the estimates of the simulation of this design. The filled densities are the estimates, the line are the distribution of the simulated estimand.


```{r}
#ggplot(testBoot)+geom_density(aes(x=estimate,fill=term),alpha=.2)
testBoot <- testBoot%>% mutate(estimand=case_when(term=="T2-T1"~TE.21,
                                                           term=="T2-C"~TE.20,
                                                           term=="T1-C"~TE.10))
ggdensity(data=testBoot,x="estimate",fill="term",rug=TRUE)+geom_density(aes(x=estimand,color=term))

```




And we can compute the power through simulation. The power of this experiment for 5% of type II error rate adjustin

```{r}
testBoot %>% group_by(term) %>% mutate(estimand=case_when(term=="T2-T1"~TE.21,
                                                           term=="T2-C"~TE.20,
                                                           term=="T1-C"~TE.10)) %>% 
                                  summarise(bias=mean(estimate-estimand),
                                            rmse=sqrt(mean((estimate - estimand)^2)),
                                            #power = mean(p.value <= 0.05),
                                            power  = mean(adj.p.value<=.05),
                                            coverage = mean(estimand <= point.conf.high & estimand >= point.conf.low),
                                            #coverage = mean(estimand <= conf.high & estimand >= conf.low)
                                          ) %>% flextable()

# 
# ggplot(testBoot)+stat_ecdf(aes(x=adj.p.value))+facet_wrap(~term)+geom_vline(aes(xintercept=.05))
# testBoot$adj.p.value
```

In a constant treatment effect framework and simpler but very similar data generating process, we have 77% power for a 5% risk of type 2 error to detect an effect of 6pp on application to any childcare.



```{r eval=F}


BootConstantITT <- function(ATE1=0,ATE2=.05,nboot=500,N=1850){
  
  results <- c()
  N = {{N}}
  for (boot in 1:nboot){
Educ2 = rbinom(N, size = 1, prob = HighSES$coefficients[1])

#Define intention to use as a binary variable with conditional probability different by education, drawn from the regression tables
Intend = rbinom(N,size=1,
                prob=Educ2*intention$coefficients["Educ2High-SES"]+
                  (1-Educ2)*intention$coefficients["Educ2Low-SES"])

#define Blocks with the intersection of the two variables

block=case_when(
                (Educ2==0 & Intend==0)~0,
                (Educ2==0 & Intend==1)~1,
                (Educ2==1 & Intend==0)~2,
                (Educ2==1 & Intend==1)~3
              )

# We can define the potential outcome in the absence of the program similarly:

Y0.star =
             case_when(
              (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
              (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
              (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
              (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
)

Y0=rbinom(N,size=1,prob=Y0.star)

# We use block random assignment
Z = block_ra(blocks=block, prob_each = c(.34,.33,.33), conditions = c("0", "1", "2"))

# Like in our results, let's simulate a null effect of T1 and a 5PP itt of T2
# 

Y1 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,0+{{ATE1}},sd=.02))



Y2 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,0+{{ATE2}},sd=.02))


Y.obs=case_when(Z==0~Y0,Z==1~Y1,Z==2~Y2)


db0 <- data.frame(Educ2,Intend,block,Y.obs,Y1,Y2,Z,Y0,Y0.star)

# like in our analysis, we build pair of comparison
db0 <- db0 %>% mutate(id=cur_group_rows()) 

T2T1 <- db0 %>% filter(Z %in% c(1,2)) %>% mutate(SubSample="T2-T1",Z1=ifelse(Z==2,1,0))
T2T0 <- db0 %>% filter(Z %in% c(0,2)) %>% mutate(SubSample="T2-C",Z1=ifelse(Z==2,1,0))
T1T0 <- db0 %>% filter(Z %in% c(0,1)) %>% mutate(SubSample="T1-C",Z1=ifelse(Z==1,1,0))

StackedDB <- bind_rows(T2T1,T2T0,T1T0) %>% mutate(SubSampleStrata=interaction(SubSample,block),
                                                  StrataWave=block,
                                                  weights=1
                                                  )


estimates <- ITTSimultaneous(Y="Y.obs",treat = "Z1",DB=StackedDB,weights = "weights")

results <- bind_rows(results,estimates$Tidy %>% mutate(Boot=boot))
  }
  return(results)
}


BootConstantITT(nboot = 10)



```



```{r eval=F}

N <- 1850

outcome_means <- c(0.75, .8, .85)
sd_i <- sqrt(.75*.25)
outcome_sds <- c(0, 0, 0)

# 
# population <- fabricate(
#   N = N,
#   latent_intend = runif(N, 0, 1),
#   SES = rbinom(N,1,.6+rnorm(N)),
#   turnout = draw_binary(prob = ifelse(latent_intend < .6, 0.6, 0.75), N=N)
# )
# 

#table(PostDB$IntendUse,PostDB$Educ2)

intention <- feols(Intend~0+Educ2,MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)))

HighSES <- feols(HighEduc~1,MainDB)

# High SES represent 60% of the population, 86% of them intend to use childcare, 71% of low SES intend to use childcare.

# Using data from the control group, we can estimate the conditional means for these subgroups

C.means <- feols(ECSApp~0+i(Intend,Educ2),MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)) %>% filter(Assignment=="Control"))


# We think application baseline are divided into these 4 subgroups

Low.NoIntend <- C.means$coefficients["Intend::0:Educ2::Low-SES"]
High.NoIntend <- C.means$coefficients["Intend::0:Educ2::High-SES"]
Low.Intend <- C.means$coefficients["Intend::1:Educ2::Low-SES"]
High.Intend <- C.means$coefficients["Intend::1:Educ2::High-SES"]

U <- rnorm(N,HighSES$coefficients[1],sqrt(HighSES$coefficients[1]))

Educ2 = rbinom(N, size = 1, prob = HighSES$coefficients[1])
Intend = rbinom(N,size=1,
                prob=Educ2*intention$coefficients["Educ2High-SES"]+
                  (1-Educ2)*intention$coefficients["Educ2Low-SES"])

Y0 = rbinom(N,
           size=1,
           prob=
             case_when(
              (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
              (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
              (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
              (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
))

block=case_when((Educ2==0 & Intend==0)~0,
                                                 (Educ2==0 & Intend==1)~1,
                                                 (Educ2==1 & Intend==0)~2,
                                                 (Educ2==1 & Intend==1)~3
                                                 )


Y1 <- Y+ Educ2*.05+(1-Educ2)*(Z==1)*.05+Educ2*(Z==2)*.1+(1-Educ2)*(Z==2)*.1+(1-Educ2)*(1-Intend)*.2*(Z==2)


Z = block_ra(blocks=block, prob_each = c(.34,.33,.33), conditions = c("0", "1", "2"))



u_1 = rnorm(N, 0, outcome_sds[1L]) 
u_2 = rnorm(N, 0, outcome_sds[2L]) 
u_3 = rnorm(N, 0, outcome_sds[3L]) 
u = rnorm(N) * sd_i


feols(Y1~Z|block,data.frame(Y1,block,Z)) %>% modelsummary()



# 
# 
# multi_arm_design <- population + potential_outcomes + assignment + 
#   reveal_Y + estimand + estimator
# 
# diagnosis <- diagnose_design(multi_arm_design, sims = 1000)



```

