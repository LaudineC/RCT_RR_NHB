---
title: "Power for IV"
output: html_notebook
---

https://chabefer.github.io/STCI/RCT.html

# Simple RCT with 2 arms

```{r}
param <- c(8,.5,.28,1500,0.9,0.01,0.05,0.05,0.05,0.1)
names(param) <- c("barmu","sigma2mu","sigma2U","barY","rho","theta","sigma2epsilon","sigma2eta","delta","baralpha")

set.seed(1234)
N <-1000
mu <- rnorm(N,param["barmu"],sqrt(param["sigma2mu"]))
UB <- rnorm(N,0,sqrt(param["sigma2U"]))
yB <- mu + UB 
YB <- exp(yB)
Ds <- rep(0,N)
Ds[YB<=param["barY"]] <- 1 
epsilon <- rnorm(N,0,sqrt(param["sigma2epsilon"]))
eta<- rnorm(N,0,sqrt(param["sigma2eta"]))
U0 <- param["rho"]*UB + epsilon
y0 <- mu +  U0 + param["delta"]
alpha.i <- param["baralpha"]+  param["theta"]*mu + eta
y1 <- y0+alpha.i
Y0 <- exp(y0)
Y1 <- exp(y1)
# randomized allocation of 50% of individuals
Rs <- runif(N)
R <- ifelse(Rs<=.5,1,0)
y <- y1*R+y0*(1-R)
Y <- Y1*R+Y0*(1-R)


```



```{r}

MDE.var <- function(alpha,kappa,varE,oneside){
  if (oneside==TRUE){
    MDE <- (qnorm(kappa)+qnorm(1-alpha))*sqrt(varE)
  }
  if (oneside==FALSE){
    MDE <- (qnorm(kappa)+qnorm(1-alpha/2))*sqrt(varE)
  }
  return(MDE)
}
MDE <- function(N,alpha,kappa,CE,oneside){
  if (oneside==TRUE){
    MDE <- (qnorm(kappa)+qnorm(1-alpha))*sqrt(CE/N)
  }
  if (oneside==FALSE){
    MDE <- (qnorm(kappa)+qnorm(1-alpha/2))*sqrt(CE/N)
  }
  return(MDE)
}

alpha <- 0.05
kappa <- 0.8
MDE.N.oneside <- sapply(varE.N,MDE.var,alpha=alpha,kappa=kappa,oneside=TRUE)
MDE.N.twoside <- sapply(varE.N,MDE.var,alpha=alpha,kappa=kappa,oneside=FALSE)
power.sample$MDE <- c(MDE.N.oneside,MDE.N.twoside)


CE.BF.fun <- function(p,varYb){
  return(varYb/(p*(1-p)))
}

MDE.BF.fun <- function(p,varYb,...){
  return(MDE(CE=CE.BF.fun(p=p,varYb=varYb),...))
}
```


```{r}
ggplot() +
  xlim(0,1) +
  ylim(0,1) +
  geom_function(aes(color="100"),fun=MDE.BF.fun,args=list(N=100,varYb=var(yB),alpha=alpha,kappa=kappa,oneside=FALSE)) +
  geom_function(aes(color="1000"),fun=MDE.BF.fun,args=list(N=1000,varYb=var(yB),alpha=alpha,kappa=kappa,oneside=FALSE)) +
  geom_function(aes(color="10000"),fun=MDE.BF.fun,args=list(N=10000,varYb=var(yB),alpha=alpha,kappa=kappa,oneside=FALSE)) +
  geom_function(aes(color="100000"),fun=MDE.BF.fun,args=list(N=100000,varYb=var(yB),alpha=alpha,kappa=kappa,oneside=FALSE)) +
  scale_color_discrete(name="N") +
  ylab("MDE") +
  xlab("p") +
  theme_bw()
```


Theorem 3.16 (Asymptotic Distribution of \$\hat\{\Delta\} ${ }^{\wedge} \mathbf{Y} \_$\{Wald\}\$) 
Under Assumptions 3.9, 3.10, 3.11, 3.12, we have:

$$
\sqrt{N}\left(\hat{\Delta}_{\text {Wald }}^Y-\Delta_{L A T E}^Y\right) \stackrel{d}{\rightarrow} \mathcal{N}\left(0, \frac{1}{\left(p_1^D-p_0^D\right)^2}\left[\left(\frac{p^D}{p^R}\right)^2 \frac{\mathbf{V}\left[Y_i \mid R_i=0\right]}{1-p^R}+\left(\frac{1-p^D}{1-p^R}\right)^2 \frac{\mathbf{V}\left[Y_i \mid R_i=1\right]}{p^R}\right]\right)
$$


Adding Assumption 3.13, the variance of the Wald estimator can be further decomposed as follows:

$$
\begin{aligned}
\sigma_{\hat{\Delta}_{\text {Wald }}^Y}^2 & =\left(\frac{p^D}{p^R}\right)^2 \frac{\mathbf{V}\left[Y_i^0 \mid T_i=C\right]}{p^C\left(1-p^R\right)}+\left(\frac{1-p^D}{1-p^R}\right)^2 \frac{\mathbf{V}\left[Y_i^1 \mid T_i=C\right]}{p^C p^R} \\
& +\frac{\left(p^{A T}\left(1-p^R\right)-p^{N T} p^R\right)^2+p^R\left(1-p^R\right)}{\left(p^C p^R\left(1-p^R\right)\right)^2}\left[p^{A T} \mathbf{V}\left[Y_i^1 \mid T_i=A T\right]+p^{N T} \mathbf{V}\left[Y_i^0 \mid T_i=N T\right]\right]
\end{aligned}
$$

with $p^D=\operatorname{Pr}\left(D_i=1\right), p^R=\operatorname{Pr}\left(R_i=1\right), p_1^D=\operatorname{Pr}\left(D_i=1 \mid R_i=1\right), p_0^D=\operatorname{Pr}\left(D_i=1 \mid R_i=0\right)$, $p^t=\operatorname{Pr}\left(T_i=t\right)$, with $t \in\{A T, N T, C, D\}$.

Proof. See Section A.2.3.
Remark. Theorem 3.16 shows that the effective sample size of an encouragement design is equal to the number of compliers. Indeed, the denominator of the variance of the Wald Estimatior depends on $p_1^D-p_0^D$, which is an estimate of the proportion of compliers, under Assumption 3.13.




In encouragement designs, we can make use Theorem 3.16 to show that:

$$
\mathbf{V}\left[\hat{\Delta}_{W a l d}^Y\right] \approx \frac{1}{N} \frac{1}{p^E} \frac{1}{\left(p_1^D-p_0^D\right)^2}\left[\left(\frac{p^D}{p^R}\right)^2 \frac{\mathbf{V}\left[Y_i \mid E_i=1, R_i=0\right]}{1-p^R}+\left(\frac{1-p^D}{1-p^R}\right)^2 \frac{\mathbf{V}\left[Y_i \mid E_i=1, R_i=1\right]}{p^R}\right.
$$

with $p^E=\operatorname{Pr}\left(E_i=1\right), p^D=\operatorname{Pr}\left(D_i=1 \mid E_i=1\right), p^R=\operatorname{Pr}\left(R_i=1 \mid E_i=1\right)$,
$p_0^D=\operatorname{Pr}\left(D_i=1 \mid R_i=0, E_i=1\right)$ and $p_1^D=\operatorname{Pr}\left(D_i=1 \mid R_i=1, E_i=1\right)$. Note that $N$ corresponds to the size of the sample including the ineligible individuals which do not enter in the estimation of the treatment effect of the program. MDEs and minimum required sample size can also be expressed in terms of $N^E=N p^E$, the size of the sample in terms of eligible units.

As with eligibility designs, there is a large number of parameters to find in order to compute this variance estimator. We need to postulate a value for $p^E$ (unless we look for information on the sample size of the eligible population participating in the experiment, in which case we set $p^E=1$ and $N=N^E$ in the above formula), a value for $p^D$, for $p^R$ and for $p_1^D$. For estimating $p^E$, we are going to choose the proportion of individuals eligible to the program $\left(\hat{p}^E=\operatorname{Pr}\left(y_i^B \leq \bar{y}\right)\right)$. For $p^D$, we know that:

$$
p^D=\operatorname{Pr}\left(D_i=1 \mid E_i=1\right)=\operatorname{Pr}\left(D_i=1 \mid R_i=1, E_i=1\right) \operatorname{Pr}\left(R_i=1 \mid E_i=1\right)+\operatorname{Pr}\left(D_i=1 \mid R_i=0, E_i=\right.
$$

. Since we can vary $p^R$, we only need to settle on a value for $p_1^D$ and $p_0^D$. We are going to choose their actual values in the sample, $\operatorname{Pr}\left(D_i=1 \mid R_i=1, E_i=1\right)$ and $\operatorname{Pr}\left(D_i=1 \mid R_i=0, E_i=1\right)$, or $\hat{p}_1^D=1$ and $\hat{p}_0^D=0.23$. In real life applications, this choice is much more difficult. It can for example be based on pilot studies where the response rate to the encouragement is tested. Finally, we are going to assume that all conditional variances are equal to the pre-treatment variance among eligibles: we use $\hat{\mathbf{V}}\left[y_i^B \mid E_i=1\right]=0.18$ as an estimate of $\hat{\mathbf{V}}\left[y_i \mid R_i=1, E_i=1\right]=0.29$ and $\hat{\mathbf{V}}\left[y_i \mid R_i=0, E_i=1\right]=$ 0.18 .

We can now write $C(E)$ for the total sample size $N$ (set $p^E=1$ for $N=N^E$ ):

$$
\hat{C}\left(\hat{\Delta}_{\text {Wald }}^Y\right)=\frac{1}{\hat{p}^E} \frac{1}{\left(\hat{p}_1^D-\hat{p}_0^D\right)^2}\left[\left(\frac{p_1^D p^R+p_0^D\left(1-p^R\right)}{p^R}\right)^2 \frac{\hat{\mathbf{V}}\left[y_i^B \mid E_i=1\right]}{1-p^R}\right.
$$






```{r}

Nc <- nrow(PostDBT2C %>% filter(Assignment=="Control"))
Nt2 <- nrow(PostDBT2C %>% filter(Assignment=="T2"))



declaration_10.1 <-
  declare_model(
    N = Nc+Nt2,
    U = rnorm(N),
    potential_outcomes(Y ~  0.15 * Z + U)
  ) +
  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +
  declare_assignment(Z = complete_ra(N)) +
  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +
  declare_estimator(Y ~ Z, inquiry = "ATE")




```


```{r}
diagnosands <- declare_diagnosands(power = mean(p.value <= 0.05))

diagnosis <- 
  diagnose_design(declaration_10.1, 
                  diagnosands = diagnosands)

diagnosis
```
```{r}
ICC <- 0.9

declaration_18.5 <-
  declare_model(
    cluster =
      add_level(
        N = 10,
        cluster_size = rep(seq(10, 50, 10), 2),
        cluster_shock =
          scale(cluster_size + rnorm(N, sd = 5)) * sqrt(ICC),
        cluster_tau = rnorm(N, sd = sqrt(ICC))
      ),
    individual =
      add_level(
        N = cluster_size,
        individual_shock = rnorm(N, sd = sqrt(1 - ICC)),
        individual_tau = rnorm(N, sd = sqrt(1 - ICC)),
        Y_Z_0 = cluster_shock + individual_shock,
        Y_Z_1 = Y_Z_0 + cluster_tau + individual_tau
      )
  ) +
  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0)) +
  declare_assignment(Z = block_and_cluster_ra(clusters = cluster, blocks = cluster_size)) +
  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +
  declare_estimator(Y ~ Z,
                    clusters = cluster,
                    inquiry = "ATE")


diagnosis_18.5 <-
  declaration_18.5 |>
  redesign(ICC = seq(0.1, 0.9, by = 0.4)) |> 
  diagnose_designs()


```



```{r}


DeclareBasicPOSAJE <- 
  
  
M <-   declare_model(
                      N=1850,
                      type = rep(c("Never-Takers","Compliers"),
                                 c(.5,.4)*N
                                 ),
                      U = rnorm(N),
                      potential_outcomes(
                      Y ~ case_when(
                                    type == "Compliers"~empirical_mean+.05*D+U,
                                    type == "Never-Takers"~empirical_mean+U,
                                  ),
                      conditions = list(D = c(0,1))
                      ),
                      potential_outcomes(
                        D~case_when(Z == 1 & type == "Compliers"~1,
                                    Z == 1 & type == "Never-Takers"~0,
                                    Z == 0 ~0,
                                    ),
                        conditions = list(Z=c(0,1))
                      )
                  )

I <-     declare_inquiry(
    ATE = mean(Y_D_1 - Y_D_0),
    LATE = mean(Y_D_1[type == "Compliers"] - Y_D_0[type == "Compliers"])) +
  declare_assignment(Z = conduct_ra(N = N)) +
  declare_measurement(D = reveal_outcomes(D ~ Z),
                      Y = reveal_outcomes(Y ~ D))
A <-   declare_assignment(Z = conduct_ra(N = N)) +
       declare_measurement(D = reveal_outcomes(D ~ Z),
                            Y = reveal_outcomes(Y ~ D)) 

D <-    declare_estimator(
    Y ~ D | Z,
    .method = iv_robust,
    inquiry = c("ATE", "LATE"),
    label = "Two stage least squares"
  ) 


PosajeDesign <- M+I+A+D


diagnose_design(PosajeDesign)



    declare_inquiry(
    ATE = mean(Y_D_1 - Y_D_0),
    LATE = mean(Y_D_1[type == "Compliers"] - Y_D_0[type == "Compliers"])) +
  declare_assignment(Z = conduct_ra(N = N)) +
  declare_measurement(D = reveal_outcomes(D ~ Z),
                      Y = reveal_outcomes(Y ~ D)) +

    declare_estimator(
    Y ~ D | Z,
    .method = iv_robust,
    inquiry = c("ATE", "LATE"),
    label = "Two stage least squares"
  ) +
  declare_estimator(
    Y ~ D,
    .method = lm_robust,
    inquiry = c("ATE", "LATE"),
    label = "As treated"
  ) +
  declare_estimator(
    Y ~ D,
    .method = lm_robust,
    inquiry = c("ATE", "LATE"),
    subset = D == Z,
    label = "Per protocol"
  )


diagnose_design(DeclareBasicPOSAJE)



declaration_18.8 <-
  declare_model(
    N = 100,
    type = 
      rep(c("Always-Taker", "Never-Taker", "Complier", "Defier"),
          c(0.2, 0.2, 0.6, 0.0)*N),
    U = rnorm(N),
    # potential outcomes of Y with respect to D
    potential_outcomes(
      Y ~ case_when(
        type == "Always-Taker" ~ -0.25 - 0.50 * D + U,
        type == "Never-Taker" ~ 0.75 - 0.25 * D + U,
        type == "Complier" ~ 0.25 + 0.50 * D + U,
        type == "Defier" ~ -0.25 - 0.50 * D + U
      ),
      conditions = list(D = c(0, 1))
    ),
    # potential outcomes of D with respect to Z
    potential_outcomes(
      D ~ case_when(
        Z == 1 & type %in% c("Always-Taker", "Complier") ~ 1,
        Z == 1 & type %in% c("Never-Taker", "Defier") ~ 0,
        Z == 0 & type %in% c("Never-Taker", "Complier") ~ 0,
        Z == 0 & type %in% c("Always-Taker", "Defier") ~ 1
      ),
      conditions = list(Z = c(0, 1))
    )
  ) +
  declare_inquiry(
    ATE = mean(Y_D_1 - Y_D_0),
    CACE = mean(Y_D_1[type == "Complier"] - Y_D_0[type == "Complier"])) +
  declare_assignment(Z = conduct_ra(N = N)) +
  declare_measurement(D = reveal_outcomes(D ~ Z),
                      Y = reveal_outcomes(Y ~ D)) +
  declare_estimator(
    Y ~ D | Z,
    .method = iv_robust,
    inquiry = c("ATE", "CACE"),
    label = "Two stage least squares"
  ) +
  declare_estimator(
    Y ~ D,
    .method = lm_robust,
    inquiry = c("ATE", "CACE"),
    label = "As treated"
  ) +
  declare_estimator(
    Y ~ D,
    .method = lm_robust,
    inquiry = c("ATE", "CACE"),
    subset = D == Z,
    label = "Per protocol"
  )

diagnose_design(declaration_18.8)


```







Let's say that we want to test one treatment arm against another for a binary outcome with proportion p=.7 (e.g. ECSApp).
We want $\alpha=.05$, power $\kappa=.8$. The standard deviation of a binary variable with mean .7 is $\sqrt{p(1-p)}=\sqrt{.7\times.3}=$`r sqrt(.7*.3)`. We plug the 40% $R^2$ and 9 blocks.



So we roughly need a 1000 units in pairwise comparison or 1500 in total if we do not account for much design effect and correlation.
Still, this is consistent with the initial estimates.

If we want to make some clear power computation that use some information from the control group to simulate data that closely match what we observe, and simulate the experiment 500 times generating new samples, assignments and treatment effects then running the same model as the real paper (with the same function).

## Model :

We specify a population of size $N$ where a unit $i$ has a potential outcome, $Y_i(Z=0)$, when it remains untreated and Z(z=1,2) potential outcomes defined according to the treatment that it receives. The effect of each treatment on the outcome of unit $i$ is equal to the difference in the potential outcome under treatment condition $z$ and the control condition: $Y_i(Z=z)−Y_i(Z=0)$.

## inquiry 


We are interested in all of the pairwise comparisons between arms: $E\left[Y(z)−Y(z^\prime)\right]$, for all $z,z^\prime \in \{0,1,2\}$


## Data strategy:

We randomly assign $\frac{k}{N}$ units to each of the treatment arms, with blocking.

## Answer strategy:

We take every pairwise difference in means corresponding to the specific estimand. 

We simulate data that closely resemble ours with a bit of simplification for clarity.

The algorithm of the function can be described as followed:

1) estimate the share of High/Low education and Intention to use in the control group.
2) in the 


```{r}

p_load(foreach)
p_load(doParallel)


s.size <- nrow(MainDB)

# get number of cores
numCores <- parallel::detectCores() # Requires library(parallel)

#print(numCores)
registerDoParallel(numCores-2)

# Get the average outcome by intention and SES Status
C.means <- feols(ECSApp~0+i(Intend,Educ2),MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)) %>% filter(Assignment=="Control"),se="hetero")

# Get the compliance rate by intention to use and SES status
D.means <- feols(Suivi_administratif1_0~0+i(Intend,Educ2),MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)) %>% filter(Assignment=="T2"),se="hetero")


modelsummary(list("Application"=C.means,"Use administrative support"=D.means),gof_map = c("r.squared","rmse","nobs"))

```


```{r}
# We think application baseline are divided into these 4 subgroups

Low.NoIntend <- C.means$coefficients["Intend::0:Educ2::Low-SES"]
High.NoIntend <- C.means$coefficients["Intend::0:Educ2::High-SES"]
Low.Intend <- C.means$coefficients["Intend::1:Educ2::Low-SES"]
High.Intend <- C.means$coefficients["Intend::1:Educ2::High-SES"]




# This function takes a constant ATE for each treatment arms, number of monte-carlo simulations, sample size and seed for replication.
# It generate news random data, assignment and estimate the treatment effects the same way we do with our analysis.
# It returns a dataframe with all estimates, standard errors, etc adjusted for simultaneous inference like we do in the paper.

# We run two basic regression to get the share of high education parents and intention to use by education in the control group.

HighSES <- feols(HighEduc~1,MainDB %>% filter(Assignment=="Control"))

intention <- feols(Intend~0+Educ2,MainDB %>% filter(Assignment=="Control")%>% mutate(Intend=ifelse(IntendUse!="Else",1,0)))




BootConstantITT <- function(ATE1=0,ATE2=.05,nboot=500,N=1850,seed=666){
  
  results <- c()
  N = {{N}}

  set.seed({{seed}})
  foreach(n.boot= 1:{{nboot}},.combine=rbind) %dopar% {
 
    Educ2 = rbinom(N, size = 1, prob = HighSES$coefficients[1])

#Define intention to use as a binary variable with conditional probability different by education, drawn from the regression tables
Intend = rbinom(N,size=1,
                prob=Educ2*intention$coefficients["Educ2High-SES"]+
                  (1-Educ2)*intention$coefficients["Educ2Low-SES"])

#define Blocks with the intersection of the two variables

block=case_when(
                (Educ2==0 & Intend==0)~0,
                (Educ2==0 & Intend==1)~1,
                (Educ2==1 & Intend==0)~2,
                (Educ2==1 & Intend==1)~3
              )

# We can define the potential outcome in the absence of the program similarly:

Y0.star =
             case_when(
              (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
              (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
              (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
              (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
)

Y0=rbinom(N,size=1,prob=Y0.star)

# We use block random assignment
Z = block_ra(blocks=block, prob_each = c(.34,.33,.33), conditions = c("0", "1", "2"))

# Like in our results, let's simulate a null effect of T1 and a 5PP itt of T2
# 

Y1 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,0+{{ATE1}},sd=.02))



Y2 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,0+{{ATE2}},sd=.02))


Y.obs=case_when(Z==0~Y0,Z==1~Y1,Z==2~Y2)


db0 <- data.frame(Educ2,Intend,block,Y.obs,Y1,Y2,Z,Y0,Y0.star) %>% mutate(TE.21=Y2-Y1,TE.10=Y1-Y0,TE.20=Y2-Y0)

# like in our analysis, we build pair of comparison
db0 <- db0 %>% mutate(id=cur_group_rows()) 

T2T1 <- db0 %>% filter(Z %in% c(1,2)) %>% mutate(SubSample="T2-T1",Z1=ifelse(Z==2,1,0))
T2T0 <- db0 %>% filter(Z %in% c(0,2)) %>% mutate(SubSample="T2-C",Z1=ifelse(Z==2,1,0))
T1T0 <- db0 %>% filter(Z %in% c(0,1)) %>% mutate(SubSample="T1-C",Z1=ifelse(Z==1,1,0))

StackedDB <- bind_rows(T2T1,T2T0,T1T0) %>% mutate(SubSampleStrata=interaction(SubSample,block),
                                                  StrataWave=block,
                                                  weights=1
                                                  )


estimates <- ITTSimultaneous(Y="Y.obs",treat = "Z1",DB=StackedDB,weights = "weights")

results <- estimates$Tidy %>% mutate(Boot=n.boot)

estimand <- StackedDB %>% group_by(SubSample) %>% summarise(TE.21=mean(TE.21,na.rm=T),TE.20=mean(TE.20,na.rm=T),TE.10=mean(TE.10,na.rm=T))

results <- results %>% left_join(estimand,by=c("term"="SubSample"))

#results %>% left_join(estimand,by=c("term"="SubSample")) #%>% mutate(bias=estimate-estimand)


  } -> All.results
  
  return(All.results)

}

testBoot <- BootConstantITT(nboot = 500,ATE1 = .05,ATE2=.1,N=nrow(MainDB),seed = 1312)

```


We can plot the estimates of the simulation of this design. The filled densities are the estimates, the line are the distribution of the simulated estimand.


```{r}
#ggplot(testBoot)+geom_density(aes(x=estimate,fill=term),alpha=.2)
testBoot <- testBoot%>% mutate(estimand=case_when(term=="T2-T1"~TE.21,
                                                           term=="T2-C"~TE.20,
                                                           term=="T1-C"~TE.10))

ggdensity(data=testBoot,x="estimate",fill="term",rug=TRUE)+geom_density(aes(x=estimand,color=term))

```




And we can compute the power through simulation. The power of this experiment for 5% of type II error rate adjustin

```{r}
testBoot %>% group_by(term) %>% mutate(estimand=case_when(term=="T2-T1"~TE.21,
                                                           term=="T2-C"~TE.20,
                                                           term=="T1-C"~TE.10)) %>% 
                                  summarise(bias=mean(estimate-estimand),
                                            rmse=sqrt(mean((estimate - estimand)^2)),
                                           power  = mean(adj.p.value<.05),
                                            coverage = mean(estimand <= conf.high & estimand >= conf.low)
                                          ) %>% flextable()

# 
# testBoot$adj.p.value
```

```{r}
ggplot(testBoot)+geom_histogram(aes(x=adj.p.value))+facet_wrap(~term)
```



In a constant treatment effect framework and simpler but very similar data generating process, we have 77% power for a 5% risk of type 2 error to detect an effect of 6pp on application to any childcare.


```{r}

BootConstantLATE <- function(TakeUp=0,ATE2=.1,nboot=500,N=950,seed=666){
  
  results <- c()
  N = {{N}}

  set.seed({{seed}})
  foreach(n.boot= 1:{{nboot}},.combine=rbind) %dopar% {
 
    Educ2 = rbinom(N, size = 1, prob = HighSES$coefficients[1])

#Define intention to use as a binary variable with conditional probability different by education, drawn from the regression tables
Intend = rbinom(N,size=1,
                prob=Educ2*intention$coefficients["Educ2High-SES"]+
                  (1-Educ2)*intention$coefficients["Educ2Low-SES"])

#define Blocks with the intersection of the two variables

block=case_when(
                (Educ2==0 & Intend==0)~0,
                (Educ2==0 & Intend==1)~1,
                (Educ2==1 & Intend==0)~2,
                (Educ2==1 & Intend==1)~3
              )

# We can define the potential outcome in the absence of the program similarly:

Y0.star =
             case_when(
              (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
              (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
              (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
              (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
)

Y0=rbinom(N,size=1,prob=Y0.star)

LatentCompliance <- case_when(
              (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  D.means$se["Intend::1:Educ2::High-SES"]),
              (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   D.means$se["Intend::1:Educ2::Low-SES"]),
              (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,D.means$se["Intend::0:Educ2::High-SES"]),
              (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, D.means$se["Intend::0:Educ2::Low-SES"])
)




# We use block random assignment
Z = block_ra(blocks=block, prob_each = c(.34,.33,.33), conditions = c("0", "1", "2"))

# Like in our results, let's simulate a null effect of T1 and a 5PP itt of T2
# 

D1 = ifelse(Z==2,rbinom(N,1,LatentCompliance),0)
  

Y2 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,0+{{ATE2}},sd=.02))


Y.obs=case_when(Z==0~Y0,Z==1~Y1,Z==2~Y2)


db0 <- data.frame(Educ2,Intend,block,Y.obs,Y1,Y2,Z,Y0,Y0.star) %>% mutate(TE.21=Y2-Y1,TE.10=Y1-Y0,TE.20=Y2-Y0)

# like in our analysis, we build pair of comparison
db0 <- db0 %>% mutate(id=cur_group_rows()) 

T2T1 <- db0 %>% filter(Z %in% c(1,2)) %>% mutate(SubSample="T2-T1",Z1=ifelse(Z==2,1,0))
T2T0 <- db0 %>% filter(Z %in% c(0,2)) %>% mutate(SubSample="T2-C",Z1=ifelse(Z==2,1,0))
T1T0 <- db0 %>% filter(Z %in% c(0,1)) %>% mutate(SubSample="T1-C",Z1=ifelse(Z==1,1,0))

StackedDB <- bind_rows(T2T1,T2T0,T1T0) %>% mutate(SubSampleStrata=interaction(SubSample,block),
                                                  StrataWave=block,
                                                  weights=1
                                                  )


estimates <- ITTSimultaneous(Y="Y.obs",treat = "Z1",DB=StackedDB,weights = "weights")

results <- estimates$Tidy %>% mutate(Boot=n.boot)

estimand <- StackedDB %>% group_by(SubSample) %>% summarise(TE.21=mean(TE.21,na.rm=T),TE.20=mean(TE.20,na.rm=T),TE.10=mean(TE.10,na.rm=T))

results <- results %>% left_join(estimand,by=c("term"="SubSample"))

#results %>% left_join(estimand,by=c("term"="SubSample")) #%>% mutate(bias=estimate-estimand)


  } -> All.results
  
  return(All.results)

}

```


## Power for one treatment arm

Consider the simple linear regression:
$$
Y_i=\mu+\beta Z_i+\upsilon_i
$$
$\mu$ gets the average in the control group and $\beta$ the treatment effect.
The formula for the MDE as given in Duflo (2008) is :
$$
MDE =(t_{1-\kappa}+t_{\alpha})\cdot\sqrt{\frac{1}{p(1-p)}}\cdot\sqrt{\frac{\sigma^2}{N}}=2.8\times SE_\beta
$$
with $\kappa$ denoting power and $\alpha$
In our setting, we have roughly 1200 households in each pair of comparison and p=.5. The only missing variable is the variance of the error term $\sigma^2$. We can plot the relationship between the two and find the level of variance that would give us a power of .8.

```{r}
variance=seq(.001,1,.001)
MDE = 2.8*sqrt(1/(.5^2))*sqrt(variance/1200)

ggplot()+geom_line(aes(x=(variance),y=MDE))+geom_hline(aes(yintercept=.04),linetype=2)+xlim(c(0,.2))


```

```{r}
modelsummary(list(feols(UseCreche~Z.c:Educ2,PostDBT2C),
                  feols(UseCreche~Z.c:Educ2,PostDBT2C,se="hetero"),
                  feols(UseCreche~Z.c:Educ2,PostDBT2C,cluster = ~StrataWave),
                  feols(UseCreche~Z.c:Educ2|StrataWave,PostDBT2C,cluster=~StrataWave),
                  feols(UseCreche~Z.c:Educ2|StrataWave,PostDBT2C,se="hetero")),fmt=4)
```
 






Our experiment has three randomised groups of roughly 600 mothers. The main outcome is application to any childcare, a binary variable with  `r round(mean(MainDB$ECSApp[MainDB$Assignment=="Control"],na.rm=T)*100)`% applying in the control group.

In a pure randomised experiment, we are interested in the coefficients $\hat{\beta}$ from the linear probability model:

$$
\begin{aligned}
Y=\alpha+\mathbf{Z}_{is}^\prime\beta+\epsilon\\
Y_{is}=\alpha_s+\sum_s\beta_sZ_{is}+\epsilon_{is}\\
\end{aligned}
$$
Where $Y_{is}$ equals 1 for application mother $i$ in the sub-sample of comparison pair $s$, with $s \in \{T_1-C,T_2-C,T_2-T_1\}$.
The matrix $\mathbf{Z}$ contains three binary vectors $Z_s$ for each treatment arm.

This regression model stacks pairs of treatment arms comparisons and retrieves a constant and a treatment coefficient for each pair.
Because Y is binary, standard errors needs to be heteroskedasticity robust and clustered at the individual level since there are repeated observation of the same individuals across pair comparisons.





```{r}
declaration_18.4 <-
  declare_model(
    N = 1200,
    X = rep(c(0, 1), each = N / 2),
    U = rnorm(N, sd = 0.25),
    potential_outcomes(Y ~ 0.05 * Z + X + U)
  ) +
  declare_assignment(
    Z = block_ra(blocks = X, block_prob = c(0.5, 0.5)),
    probs =
      obtain_condition_probabilities(assignment = Z, 
                                     blocks = X, 
                                     block_prob = c(0.5, 0.5)),
    ipw = 1 / probs
  ) +
  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +
  declare_estimator(
    Y ~ Z,
    covariates = ~ X,
    .method = lm_lin,
    weights = ipw,
    label = "Lin"
  )

diagnose_design(declaration_18.4)


```





# Most basic diagnostic

Our experiment has three randomised groups of roughly 600 mothers. The main outcome is application to any childcare, a binary variable with  `r round(mean(MainDB$ECSApp[MainDB$Assignment=="Control"],na.rm=T)*100)`% applying in the control group.

In a pure randomised experiment, we are interested in the coefficients $\hat{\beta}$ from the linear probability model:

$$
\begin{aligned}
Y=\alpha+\mathbf{Z}_{is}^\prime\beta+\epsilon\\
Y_{is}=\alpha_s+\sum_s\beta_sZ_{is}+\epsilon_{is}\\
\end{aligned}
$$
Where $Y_{is}$ equals 1 for application mother $i$ in the sub-sample of comparison pair $s$, with $s \in \{T_1-C,T_2-C,T_2-T_1\}$.
The matrix $\mathbf{Z}$ contains three binary vectors $Z_s$ for each treatment arm.

This regression model stacks pairs of treatment arms comparisons and retrieves a constant and a treatment coefficient for each pair.
Because Y is binary, standard errors needs to be heteroskedasticity robust and clustered at the individual level since there are repeated observation of the same individuals across pair comparisons.

## Model :

We specify a population of size $N$ where a unit $i$ has a potential outcome, $Y_i(Z=0)$, when it remains untreated and Z(z=1,2) potential outcomes defined according to the treatment that it receives. The effect of each treatment on the outcome of unit $i$ is equal to the difference in the potential outcome under treatment condition $z$ and the control condition: $Y_i(Z=z)−Y_i(Z=0)$.

## inquiry 


We are interested in all of the pairwise comparisons between arms: $E\left[Y(z)−Y(z^\prime)\right]$, for all $z,z^\prime \in \{0,1,2\}$


## Data strategy:

We randomly assign $\frac{k}{N}$ units to each of the treatment arms, with blocking.

## Answer strategy:

We take every pairwise difference in means corresponding to the specific estimand. 

We simulate data that closely resemble ours with a bit of simplification for clarity.

```{r, echo=TRUE}
#Sample Size
N <- nrow(MainDB %>% filter(Responded==1))

# We run two basic regression to get the share of high education parents and intention to use by education in the control group.

HighSES <- feols(HighEduc~1,MainDB)

intention <- feols(Intend~0+Educ2,MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)))



```


High SES represent `r round(HighSES$coefficients*100)`% of the population, `r round(intention$coefficients[1]*100)`% of them intend to use childcare, while only `r round(intention$coefficients[2]*100)`% of low SES do.
Using data from the control group, we can estimate the conditional means of the outcome for these subgroups:
```{r, echo=TRUE}
# 

C.means <- feols(ECSApp~0+i(Intend,Educ2),MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)) %>% filter(Assignment=="Control"),se="hetero")


D.means <- feols(Suivi_administratif1_0~0+i(Intend,Educ2),MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)) %>% filter(Assignment=="T2"),se="hetero")


# We think application baseline are divided into these 4 subgroups

Low.NoIntend <- C.means$coefficients["Intend::0:Educ2::Low-SES"]
High.NoIntend <- C.means$coefficients["Intend::0:Educ2::High-SES"]
Low.Intend <- C.means$coefficients["Intend::1:Educ2::Low-SES"]
High.Intend <- C.means$coefficients["Intend::1:Educ2::High-SES"]



```

```{r}
modelsummary(list("Application"=C.means,"Use administrative support"=D.means),gof_map = c("r.squared","rmse","nobs"))
```

Let's generate a first sample and potential outcome without intervention. We assume that our sample is *iid* (at least for now) and we first draw an education variable from a Bernoulli trial with probability given by the share of High SES in the sample. The realisation of education generates intention from a Bernoulli trial with probability depending on SES status (alternatively, we could have defined a latent propensity to use and a threshold function depending on education in a Roy model).



```{r}
# Set seed for reproducibility
set.seed(666)
# Define binary variable for education with average probability given from the HighSES regression coefficient
Educ2 = rbinom(N, size = 1, prob = HighSES$coefficients[1])

#Define intention to use as a binary variable with conditional probability different by education, drawn from the regression tables
Intend = rbinom(N,size=1,
                prob=Educ2*intention$coefficients["Educ2High-SES"]+
                  (1-Educ2)*intention$coefficients["Educ2Low-SES"])

#define Blocks with the intersection of the two variables

block=case_when(
                (Educ2==0 & Intend==0)~0,
                (Educ2==0 & Intend==1)~1,
                (Educ2==1 & Intend==0)~2,
                (Educ2==1 & Intend==1)~3
              )

# We can define the potential outcome in the absence of the program similarly:

Y0.star =
             case_when(
              (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
              (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
              (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
              (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
)

Y0=rbinom(N,size=1,prob=Y0.star)

# Y0 = rbinom(N,
#            size=1,
#            prob=
#              case_when(
#               (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
#               (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
#               (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
#               (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
# ))
# 




db0 <- data.frame(Y0,Intend,Educ2,block)

# Linear probability model of application by intention and education:
modelsummary(list("Simulated"=feols(Y0~0+i(Educ2,factor(Intend)),db0,se="hetero"),
                  "Observed"=feols(ECSApp~0+i(Educ2,factor(Intend)),MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0),
                                                                                      Educ2=ifelse(Educ2=="High-SES",1,0)
                                                                                      ),se="hetero")))

```

Comparing the simulated outcome and actual data shows that our simulation works well.

Now, let's introduce our treatment.

```{r}
# We use block random assignment
Z = block_ra(blocks=block, prob_each = c(.34,.33,.33), conditions = c("0", "1", "2"))

# Like in our results, let's simulate a null effect of T1 and a 5PP itt of T2
# 

Y1 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,0,sd=.05))



Y2 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,.05,sd=.05))


Y.obs=case_when(Z==0~Y0,Z==1~Y1,Z==2~Y2)


db0 <- data.frame(db0,Y.obs,Y1,Y2,Z)%>% mutate(TE.21=Y2-Y1,TE.10=Y1-Y0,TE.20=Y2-Y0)

# like in our analysis, we build pair of comparison
db0 <- db0 %>% mutate(id=cur_group_rows()) 

T2T1 <- db0 %>% filter(Z %in% c(1,2)) %>% mutate(SubSample="T2-T1",Z1=ifelse(Z==2,1,0))
T2T0 <- db0 %>% filter(Z %in% c(0,2)) %>% mutate(SubSample="T2-C",Z1=ifelse(Z==2,1,0))
T1T0 <- db0 %>% filter(Z %in% c(0,1)) %>% mutate(SubSample="T1-C",Z1=ifelse(Z==1,1,0))

StackedDB <- bind_rows(T2T1,T2T0,T1T0) %>% mutate(SubSampleStrata=interaction(SubSample,block),
                                                  StrataWave=block,
                                                  weights=1
                                                  )


test <- ITTSimultaneous(Y="Y.obs",treat = "Z1",DB=StackedDB,weights = "weights")

real <- ITTSimultaneous(Y="ECSApp")


modelsummary(list("Simulation"=test$ModelSummary,"Real estimates"=real$ModelSummary))

estimand <- StackedDB %>% group_by(SubSample) %>% summarise(TE.21=mean(TE.21,na.rm=T),TE.20=mean(TE.20,na.rm=T),TE.10=mean(TE.10,na.rm=T))

results <- test$Tidy %>% left_join(estimand,by=c("term"="SubSample"))


#hist(StackedDB$TE.20,na.rm=T)
#feols(Y.obs~i(Z)|block,db0)

#ITTSimultaneous()



```

There again, this simulation works well. Now we are ready to create a bootstrap function and simulate this experiment many time.

```{r, echo=T}

p_load(foreach)
p_load(doParallel)


s.size <- nrow(MainDB)

# get number of cores
numCores <- parallel::detectCores() # Requires library(parallel)

#print(numCores)
registerDoParallel(numCores-2)


# This function takes a constant ATE for each treatment arms, number of monte-carlo simulations, sample size and seed for replication.
# It generate news random data, assignment and estimate the treatment effects the same way we do with our analysis.
# It returns a dataframe with all estimates, standard errors, etc adjusted for simultaneous inference like we do in the paper.

BootConstantITT <- function(ATE1=0,ATE2=.05,nboot=500,N=1850,seed=666){
  
  results <- c()
  N = {{N}}

  set.seed({{seed}})
  foreach(n.boot= 1:{{nboot}},.combine=rbind) %dopar% {
 
    Educ2 = rbinom(N, size = 1, prob = HighSES$coefficients[1])

#Define intention to use as a binary variable with conditional probability different by education, drawn from the regression tables
Intend = rbinom(N,size=1,
                prob=Educ2*intention$coefficients["Educ2High-SES"]+
                  (1-Educ2)*intention$coefficients["Educ2Low-SES"])

#define Blocks with the intersection of the two variables

block=case_when(
                (Educ2==0 & Intend==0)~0,
                (Educ2==0 & Intend==1)~1,
                (Educ2==1 & Intend==0)~2,
                (Educ2==1 & Intend==1)~3
              )

# We can define the potential outcome in the absence of the program similarly:

Y0.star =
             case_when(
              (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
              (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
              (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
              (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
)

Y0=rbinom(N,size=1,prob=Y0.star)

# We use block random assignment
Z = block_ra(blocks=block, prob_each = c(.34,.33,.33), conditions = c("0", "1", "2"))

# Like in our results, let's simulate a null effect of T1 and a 5PP itt of T2
# 

Y1 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,0+{{ATE1}},sd=.02))



Y2 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,0+{{ATE2}},sd=.02))


Y.obs=case_when(Z==0~Y0,Z==1~Y1,Z==2~Y2)


db0 <- data.frame(Educ2,Intend,block,Y.obs,Y1,Y2,Z,Y0,Y0.star) %>% mutate(TE.21=Y2-Y1,TE.10=Y1-Y0,TE.20=Y2-Y0)

# like in our analysis, we build pair of comparison
db0 <- db0 %>% mutate(id=cur_group_rows()) 

T2T1 <- db0 %>% filter(Z %in% c(1,2)) %>% mutate(SubSample="T2-T1",Z1=ifelse(Z==2,1,0))
T2T0 <- db0 %>% filter(Z %in% c(0,2)) %>% mutate(SubSample="T2-C",Z1=ifelse(Z==2,1,0))
T1T0 <- db0 %>% filter(Z %in% c(0,1)) %>% mutate(SubSample="T1-C",Z1=ifelse(Z==1,1,0))

StackedDB <- bind_rows(T2T1,T2T0,T1T0) %>% mutate(SubSampleStrata=interaction(SubSample,block),
                                                  StrataWave=block,
                                                  weights=1
                                                  )


estimates <- ITTSimultaneous(Y="Y.obs",treat = "Z1",DB=StackedDB,weights = "weights")

results <- estimates$Tidy %>% mutate(Boot=n.boot)

estimand <- StackedDB %>% group_by(SubSample) %>% summarise(TE.21=mean(TE.21,na.rm=T),TE.20=mean(TE.20,na.rm=T),TE.10=mean(TE.10,na.rm=T))

results <- results %>% left_join(estimand,by=c("term"="SubSample"))

#results %>% left_join(estimand,by=c("term"="SubSample")) #%>% mutate(bias=estimate-estimand)


  } -> All.results
  
  return(All.results)

}

testBoot <- BootConstantITT(nboot = 500,ATE1 = .05,ATE2=.1,N=nrow(MainDB))




```

We can plot the estimates of the simulation of this design. The filled densities are the estimates, the line are the distribution of the simulated estimand.


```{r}
#ggplot(testBoot)+geom_density(aes(x=estimate,fill=term),alpha=.2)
testBoot <- testBoot%>% mutate(estimand=case_when(term=="T2-T1"~TE.21,
                                                           term=="T2-C"~TE.20,
                                                           term=="T1-C"~TE.10))
ggdensity(data=testBoot,x="estimate",fill="term",rug=TRUE)+geom_density(aes(x=estimand,color=term))

```




And we can compute the power through simulation. The power of this experiment for 5% of type II error rate adjustin

```{r}
testBoot %>% group_by(term) %>% mutate(estimand=case_when(term=="T2-T1"~TE.21,
                                                           term=="T2-C"~TE.20,
                                                           term=="T1-C"~TE.10)) %>% 
                                  summarise(bias=mean(estimate-estimand),
                                            rmse=sqrt(mean((estimate - estimand)^2)),
                                            power = mean(p.value <= 0.05),
                                            FWER.power  = mean(adj.p.value<.05),
                                            coverage = mean(estimand <= point.conf.high & estimand >= point.conf.low),
                                            FWER.coverage = mean(estimand <= conf.high & estimand >= conf.low)
                                          ) %>% flextable()

# 
 ggplot(testBoot)+geom_histogram(aes(x=p.value))+facet_wrap(~term)
# testBoot$adj.p.value
```

In a constant treatment effect framework and simpler but very similar data generating process, we have 77% power for a 5% risk of type 2 error to detect an effect of 6pp on application to any childcare.



```{r eval=F}


BootConstantITT <- function(ATE1=0,ATE2=.05,nboot=500,N=1850){
  
  results <- c()
  N = {{N}}
  for (boot in 1:nboot){
Educ2 = rbinom(N, size = 1, prob = HighSES$coefficients[1])

#Define intention to use as a binary variable with conditional probability different by education, drawn from the regression tables
Intend = rbinom(N,size=1,
                prob=Educ2*intention$coefficients["Educ2High-SES"]+
                  (1-Educ2)*intention$coefficients["Educ2Low-SES"])

#define Blocks with the intersection of the two variables

block=case_when(
                (Educ2==0 & Intend==0)~0,
                (Educ2==0 & Intend==1)~1,
                (Educ2==1 & Intend==0)~2,
                (Educ2==1 & Intend==1)~3
              )

# We can define the potential outcome in the absence of the program similarly:

Y0.star =
             case_when(
              (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
              (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
              (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
              (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
)

Y0=rbinom(N,size=1,prob=Y0.star)

# We use block random assignment
Z = block_ra(blocks=block, prob_each = c(.34,.33,.33), conditions = c("0", "1", "2"))

# Like in our results, let's simulate a null effect of T1 and a 5PP itt of T2
# 

Y1 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,0+{{ATE1}},sd=.02))



Y2 = rbinom(N,
           size=1,
           prob=Y0.star+rnorm(N,0+{{ATE2}},sd=.02))


Y.obs=case_when(Z==0~Y0,Z==1~Y1,Z==2~Y2)


db0 <- data.frame(Educ2,Intend,block,Y.obs,Y1,Y2,Z,Y0,Y0.star)

# like in our analysis, we build pair of comparison
db0 <- db0 %>% mutate(id=cur_group_rows()) 

T2T1 <- db0 %>% filter(Z %in% c(1,2)) %>% mutate(SubSample="T2-T1",Z1=ifelse(Z==2,1,0))
T2T0 <- db0 %>% filter(Z %in% c(0,2)) %>% mutate(SubSample="T2-C",Z1=ifelse(Z==2,1,0))
T1T0 <- db0 %>% filter(Z %in% c(0,1)) %>% mutate(SubSample="T1-C",Z1=ifelse(Z==1,1,0))

StackedDB <- bind_rows(T2T1,T2T0,T1T0) %>% mutate(SubSampleStrata=interaction(SubSample,block),
                                                  StrataWave=block,
                                                  weights=1
                                                  )


estimates <- ITTSimultaneous(Y="Y.obs",treat = "Z1",DB=StackedDB,weights = "weights")

results <- bind_rows(results,estimates$Tidy %>% mutate(Boot=boot))
  }
  return(results)
}


BootConstantITT(nboot = 10)



```



```{r eval=F}

N <- 1850

outcome_means <- c(0.75, .8, .85)
sd_i <- sqrt(.75*.25)
outcome_sds <- c(0, 0, 0)

# 
# population <- fabricate(
#   N = N,
#   latent_intend = runif(N, 0, 1),
#   SES = rbinom(N,1,.6+rnorm(N)),
#   turnout = draw_binary(prob = ifelse(latent_intend < .6, 0.6, 0.75), N=N)
# )
# 

#table(PostDB$IntendUse,PostDB$Educ2)

intention <- feols(Intend~0+Educ2,MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)))

HighSES <- feols(HighEduc~1,MainDB)

# High SES represent 60% of the population, 86% of them intend to use childcare, 71% of low SES intend to use childcare.

# Using data from the control group, we can estimate the conditional means for these subgroups

C.means <- feols(ECSApp~0+i(Intend,Educ2),MainDB %>% mutate(Intend=ifelse(IntendUse!="Else",1,0)) %>% filter(Assignment=="Control"))


# We think application baseline are divided into these 4 subgroups

Low.NoIntend <- C.means$coefficients["Intend::0:Educ2::Low-SES"]
High.NoIntend <- C.means$coefficients["Intend::0:Educ2::High-SES"]
Low.Intend <- C.means$coefficients["Intend::1:Educ2::Low-SES"]
High.Intend <- C.means$coefficients["Intend::1:Educ2::High-SES"]

U <- rnorm(N,HighSES$coefficients[1],sqrt(HighSES$coefficients[1]))

Educ2 = rbinom(N, size = 1, prob = HighSES$coefficients[1])
Intend = rbinom(N,size=1,
                prob=Educ2*intention$coefficients["Educ2High-SES"]+
                  (1-Educ2)*intention$coefficients["Educ2Low-SES"])

Y0 = rbinom(N,
           size=1,
           prob=
             case_when(
              (Educ2==1 & Intend==1) ~ rnorm( N, High.Intend,  C.means$se["Intend::1:Educ2::High-SES"]),
              (Educ2==0 & Intend==1) ~ rnorm( N, Low.Intend,   C.means$se["Intend::1:Educ2::Low-SES"]),
              (Educ2==1 & Intend==0) ~ rnorm( N, High.NoIntend,C.means$se["Intend::0:Educ2::High-SES"]),
              (Educ2==0 & Intend==0) ~ rnorm( N, Low.NoIntend, C.means$se["Intend::0:Educ2::Low-SES"])
))

block=case_when((Educ2==0 & Intend==0)~0,
                                                 (Educ2==0 & Intend==1)~1,
                                                 (Educ2==1 & Intend==0)~2,
                                                 (Educ2==1 & Intend==1)~3
                                                 )


Y1 <- Y+ Educ2*.05+(1-Educ2)*(Z==1)*.05+Educ2*(Z==2)*.1+(1-Educ2)*(Z==2)*.1+(1-Educ2)*(1-Intend)*.2*(Z==2)


Z = block_ra(blocks=block, prob_each = c(.34,.33,.33), conditions = c("0", "1", "2"))



u_1 = rnorm(N, 0, outcome_sds[1L]) 
u_2 = rnorm(N, 0, outcome_sds[2L]) 
u_3 = rnorm(N, 0, outcome_sds[3L]) 
u = rnorm(N) * sd_i


feols(Y1~Z|block,data.frame(Y1,block,Z)) %>% modelsummary()



# 
# 
# multi_arm_design <- population + potential_outcomes + assignment + 
#   reveal_Y + estimand + estimator
# 
# diagnosis <- diagnose_design(multi_arm_design, sims = 1000)



```

